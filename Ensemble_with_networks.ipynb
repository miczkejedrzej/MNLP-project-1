{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miczkejedrzej/MNLP-project-1/blob/main/Ensemble_with_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble\n"
      ],
      "metadata": {
        "id": "_N5_A08nJLCh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "EJob63VAJInj",
        "outputId": "386d0352-ff91-4b01-f4af-3b9eb3bc447e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-38ec8eae-3514-4cc0-b3da-71dc1059bf7c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-38ec8eae-3514-4cc0-b3da-71dc1059bf7c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving dev_df_complete.json to dev_df_complete.json\n",
            "Saving train_df_complete.json to train_df_complete.json\n",
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "'''imports '''\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder,MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "%pip install fasttext\n",
        "\n",
        "\n",
        "# The complete datasets needed\n",
        "train_df = pd.read_json('train_df_complete.json', orient=\"records\", lines=True)\n",
        "dev_df = pd.read_json('dev_df_complete.json', orient=\"records\", lines=True)\n",
        "\n",
        "\n",
        "# The logits from the base model based on the descriptions, on the training and dev set, available in the datasets folder\n",
        "# on github\n",
        "#logits_train_model_description = np.load(\"train_logits_description.npy\")\n",
        "#logits_train_model_features = np.load(\"train_logits.npy\")\n",
        "\n",
        "# The logits from the base mode based on the extracted features, on the training and dev set , available in datasets folder\n",
        "# on the github\n",
        "#logits_dev_model_descriptions = np.load(\"dev_logits_description.npy\")\n",
        "#logits_dev_model_features = np.load(\"dev_logits.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the 3 models"
      ],
      "metadata": {
        "id": "nGVxrLaSVMXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub tensorflow --quiet\n",
        "\n",
        "from huggingface_hub import login, create_repo, upload_folder\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Repo name and model file name\n",
        "repo_id = \"tgarnier067/MNLP-HW1\"\n",
        "model_name_1 = \"model_logits_features.keras\"\n",
        "model_name_2 = \"model_logits_description.keras\"\n",
        "model_name_3 = \"model_logits_photos.keras\"\n",
        "\n",
        "# Download the model from Hugging Face\n",
        "model_path_1 = hf_hub_download(repo_id=repo_id, filename=model_name_1)\n",
        "model_path_2 = hf_hub_download(repo_id=repo_id, filename=model_name_2)\n",
        "model_path_3 = hf_hub_download(repo_id=repo_id, filename=model_name_3)\n",
        "\n",
        "\n",
        "# Load the .keras model with TensorFlow\n",
        "model_logits_features = tf.keras.models.load_model(model_path_1)\n",
        "model_logits_description = tf.keras.models.load_model(model_path_2)\n",
        "model_logits_photos = tf.keras.models.load_model(model_path_3)"
      ],
      "metadata": {
        "id": "2MeOQ_FDUftn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "#from tensorflow.keras.models import load_model\n",
        "#model_logits_description = load_model(\"model_logits_description.keras\")\n",
        "#model_logits_features = load_model(\"model_logits_features.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "msIK8Z52MUGR",
        "outputId": "1c1a7c65-8083-4e6f-9e37-e4057a8c3e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-228e4f69-5b02-45cf-8120-55910e6748a9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-228e4f69-5b02-45cf-8120-55910e6748a9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model_logits_description.keras to model_logits_description.keras\n",
            "Saving model_logits_features.keras to model_logits_features.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model_logits_description"
      ],
      "metadata": {
        "id": "b_C-TQ6NJ1C1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "PubY4hEUXnUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import fasttext.util\n",
        " fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        " ft = fasttext.load_model('cc.en.300.bin')"
      ],
      "metadata": {
        "id": "MC7rmjxVkPCQ",
        "outputId": "8beda12c-99f0-4eb3-a105-658ec9fba203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "porter = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from sklearn.preprocessing import normalize\n"
      ],
      "metadata": {
        "id": "z3KU45vfmuZN",
        "outputId": "b23c67e2-394b-48af-8ed4-2b4c19d05e65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''transforming the descriptions to the embeddings space , adding the oov information'''\n",
        "def transform_description(description):\n",
        "  oov_words = 0\n",
        "  description = nltk.word_tokenize(description)\n",
        "  description = [word for word in description if word not in stop_words]\n",
        "  description = [word.lower() for word in description]\n",
        "  for word in description:\n",
        "    if word not in ft.words:\n",
        "      oov_words += 1\n",
        "  description = \" \".join(description)\n",
        "  description_vector = ft.get_sentence_vector(description)\n",
        "  description_vector = normalize(description_vector.reshape(1, -1), norm='l2')[0]\n",
        "  description_vector = np.append(description_vector, oov_words)\n",
        "  return description_vector"
      ],
      "metadata": {
        "id": "p7Lu9R33maUB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = train_df['description'].to_list()\n",
        "train_labels = train_df['label_int'].to_list()\n",
        "\n",
        "# Exctract the text and the label : Dev\n",
        "dev_texts = dev_df['description'].to_list()\n",
        "dev_labels = dev_df['label_int'].to_list()\n",
        "\n",
        "# Vectorize the texts with fasttext\n",
        "train_vectors = np.array([transform_description(text) for text in train_texts])\n",
        "dev_vectors = np.array([transform_description(text) for text in dev_texts])"
      ],
      "metadata": {
        "id": "rrlwXA8Glqy5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply the model to the data"
      ],
      "metadata": {
        "id": "scfVxajMXrFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits_dev_model_descriptions = model_logits_description.predict(dev_vectors)\n",
        "logits_train_model_description = model_logits_description.predict(train_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVV24MO5Bk5o",
        "outputId": "04c47c7e-f116-45ff-882e-f291d1e557dd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 122ms/step\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train_description = pd.DataFrame(logits_train_model_description, columns=['logit_0', 'logit_1', 'logit_2'])\n",
        "df_train_description['label'] = train_df['label_int']\n",
        "dev_df_description = pd.DataFrame(logits_dev_model_descriptions, columns=['logit_0', 'logit_1', 'logit_2'])\n",
        "dev_df_description['label'] = dev_df['label_int']\n"
      ],
      "metadata": {
        "id": "ozJhj0HSXOu8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''sanity check on the dataframe'''\n",
        "df_train_description.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "xWnvmLJ8e-RB",
        "outputId": "f2443d62-c3b4-45d6-e420-9bd5a1939efa"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    logit_0   logit_1   logit_2  label\n",
              "0  1.905099  1.534088 -3.094239      0\n",
              "1  0.760209  2.901672 -5.288947      1\n",
              "2 -0.636569  2.368679 -4.468928      1\n",
              "3  1.309631  1.982280 -3.745397      1\n",
              "4 -1.129772  2.629756 -4.753025      1\n",
              "5  1.146501  1.890622 -3.682914      1\n",
              "6  0.381403  1.764993 -3.796714      0\n",
              "7  1.686283  2.372820 -4.080890      1\n",
              "8 -1.380256  2.684189 -4.805523      1\n",
              "9  1.886965  1.921860 -3.410134      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11c4e540-49ea-4d7e-8152-8a35785b7d86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>logit_0</th>\n",
              "      <th>logit_1</th>\n",
              "      <th>logit_2</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.905099</td>\n",
              "      <td>1.534088</td>\n",
              "      <td>-3.094239</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.760209</td>\n",
              "      <td>2.901672</td>\n",
              "      <td>-5.288947</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.636569</td>\n",
              "      <td>2.368679</td>\n",
              "      <td>-4.468928</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.309631</td>\n",
              "      <td>1.982280</td>\n",
              "      <td>-3.745397</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.129772</td>\n",
              "      <td>2.629756</td>\n",
              "      <td>-4.753025</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.146501</td>\n",
              "      <td>1.890622</td>\n",
              "      <td>-3.682914</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.381403</td>\n",
              "      <td>1.764993</td>\n",
              "      <td>-3.796714</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.686283</td>\n",
              "      <td>2.372820</td>\n",
              "      <td>-4.080890</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-1.380256</td>\n",
              "      <td>2.684189</td>\n",
              "      <td>-4.805523</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.886965</td>\n",
              "      <td>1.921860</td>\n",
              "      <td>-3.410134</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11c4e540-49ea-4d7e-8152-8a35785b7d86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-11c4e540-49ea-4d7e-8152-8a35785b7d86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-11c4e540-49ea-4d7e-8152-8a35785b7d86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-74db1c72-da70-49ef-adae-879cf1e173df\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74db1c72-da70-49ef-adae-879cf1e173df')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-74db1c72-da70-49ef-adae-879cf1e173df button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train_description",
              "summary": "{\n  \"name\": \"df_train_description\",\n  \"rows\": 6251,\n  \"fields\": [\n    {\n      \"column\": \"logit_0\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5650,\n        \"samples\": [\n          -0.6306913495063782,\n          -0.727057933807373,\n          4.517135143280029\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logit_1\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5654,\n        \"samples\": [\n          -0.10069254785776138,\n          -0.9169986844062805,\n          -1.229723572731018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"logit_2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 5653,\n        \"samples\": [\n          -3.721532106399536,\n          -4.464916229248047,\n          -3.339001417160034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model_logits_features"
      ],
      "metadata": {
        "id": "6Ow7ggzUGnw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the data"
      ],
      "metadata": {
        "id": "bCTcoak0XwX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the list of explicatives variables\n",
        "list_var = ['subclass_depth', 'subclasses', 'instances_of', 'instances_of_up', 'date', 'nb_lang',\n",
        "       'descr_num_nouns', 'descr_num_verbs',\n",
        "       'descr_num_adjectives', 'descr_has_location', 'descr_has_ethnic_group',\n",
        "       'descr_has_event', 'type_cat', 'category_architecture',\n",
        "       'category_biology', 'category_comics and anime', 'category_fashion',\n",
        "       'category_films', 'category_food', 'category_geography',\n",
        "       'category_literature', 'category_media', 'category_music',\n",
        "       'category_politics', 'category_sports', 'category_transportation',\n",
        "       'category_visual arts', 'category_combined',\n",
        "       'main_country_cat'\n",
        "]\n",
        "\n",
        "# Create the X and y, train and dev\n",
        "X_train = train_df[list_var]\n",
        "y_train = train_df['label_int'].values\n",
        "\n",
        "X_dev = dev_df[list_var]\n",
        "y_dev = dev_df['label_int'].values\n",
        "\n",
        "# Selecting numerical columns from X_train (all of them are int64 or float64)\n",
        "num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "# Defining pipeline: impute Nan, then scale\n",
        "num_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "# Appling pipeline to numeric columns\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', num_pipeline, num_cols)\n",
        "])\n",
        "\n",
        "\n",
        "#adjustin the data to proper format\n",
        "X_train_processed = preprocessor.fit_transform(X_train)\n",
        "X_dev_processed = preprocessor.transform(X_dev)\n",
        "\n",
        "# float cast\n",
        "X_train_processed = X_train_processed.astype('float32')\n",
        "X_dev_processed = X_dev_processed.astype('float32')\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train, num_classes=3)\n",
        "y_dev_cat = to_categorical(y_dev, num_classes=3)"
      ],
      "metadata": {
        "id": "50qeBhnYHCCn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply the model on the data"
      ],
      "metadata": {
        "id": "Z-BxJ3keXyk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits_dev_model_features = model_logits_features.predict(X_dev_processed)\n",
        "logits_train_model_features = model_logits_features.predict(X_train_processed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NruvuxHHM2g",
        "outputId": "3bd876a6-fe0f-44d0-b74d-9ab8b63e429a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 147ms/step\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## model_logits_photos"
      ],
      "metadata": {
        "id": "og7HGSzWSAN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['image'] = train_df['image'].apply(lambda x: np.array(x))\n",
        "dev_df['image'] = dev_df['image'].apply(lambda x: np.array(x))"
      ],
      "metadata": {
        "id": "ptrm5jDYmIAq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalisation des images\n",
        "X_train_fill = np.stack(train_df['image'].to_numpy()).astype('float32') / 255.0\n",
        "y_train_fill = train_df['label']\n",
        "\n",
        "X_dev_fill = np.stack(dev_df['image'].to_numpy()).astype('float32') / 255.0\n",
        "y_dev_fill = dev_df['label']"
      ],
      "metadata": {
        "id": "oTrIPomETVMe"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits_dev_model_photos = model_logits_photos.predict(X_dev_fill)\n",
        "logits_train_model_photos = model_logits_photos.predict(X_train_fill)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROUzHUc-SSDl",
        "outputId": "98bfeba8-7ccf-495d-f983-226fcb32fa09"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\n",
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble model\n"
      ],
      "metadata": {
        "id": "7hs6yfdjV7l-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here we try to combine two classifiers, one basing on the neural network working on features extracted frrom the wikidata/wikipedia, and the second one basing on the neural network working on the embedding representation of the description of the wikipedia/wikidata entities. We combine them with a meta lerner that as training set  takes the logits for each label from both of the trained base neural networks, achieved on the train set. And the validation are the logits of these two networks acquired by predcition on the validation set."
      ],
      "metadata": {
        "id": "2aXZNt-WYBs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build and fit the ensemble model"
      ],
      "metadata": {
        "id": "QYrVYmLAYFmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "early_stop = callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "train_labels = df_train_description['label']\n",
        "dev_labels = dev_df_description['label']\n",
        "\n",
        "train_labels_nn = to_categorical(train_labels, num_classes=3)\n",
        "dev_labels_nn = to_categorical(dev_labels, num_classes=3)\n",
        "\n",
        "train_vectors = np.concatenate((logits_train_model_description, logits_train_model_features), axis=1)\n",
        "train_vectors = np.concatenate((train_vectors, logits_train_model_photos), axis=1)\n",
        "dev_vectors = np.concatenate((logits_dev_model_descriptions, logits_dev_model_features), axis=1)\n",
        "dev_vectors = np.concatenate((dev_vectors, logits_dev_model_photos), axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n",
        "#model_Ensemble = models.Sequential()\n",
        "\n",
        "#model_Ensemble.add(layers.Input(shape=(9,), name='input_layer'))\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model_Ensemble = models.Sequential([\n",
        "    layers.Input(shape=(9,)),\n",
        "    layers.Dense(16, kernel_regularizer=regularizers.l2(1e-4)),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(8, kernel_regularizer=regularizers.l2(1e-4)),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.3),\n",
        "\n",
        "    layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model_Ensemble.compile(optimizer=Adam(learning_rate=3e-4),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = model_Ensemble.fit(\n",
        "    train_vectors, train_labels_nn,\n",
        "    validation_data=(dev_vectors, dev_labels_nn),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yXcYQ7GV2mE",
        "outputId": "c6d63c4b-9d84-4c80-853b-8dff3cf5658e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - accuracy: 0.3456 - loss: 1.4492 - val_accuracy: 0.5100 - val_loss: 1.1643 - learning_rate: 3.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4977 - loss: 1.0440 - val_accuracy: 0.6233 - val_loss: 1.0310 - learning_rate: 3.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6219 - loss: 0.8461 - val_accuracy: 0.6667 - val_loss: 0.9576 - learning_rate: 3.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6854 - loss: 0.7374 - val_accuracy: 0.6633 - val_loss: 0.9075 - learning_rate: 3.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7363 - loss: 0.6505 - val_accuracy: 0.6700 - val_loss: 0.8715 - learning_rate: 3.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7909 - loss: 0.5812 - val_accuracy: 0.6833 - val_loss: 0.8410 - learning_rate: 3.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8039 - loss: 0.5248 - val_accuracy: 0.6967 - val_loss: 0.8193 - learning_rate: 3.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8219 - loss: 0.4799 - val_accuracy: 0.6967 - val_loss: 0.8008 - learning_rate: 3.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8406 - loss: 0.4470 - val_accuracy: 0.7033 - val_loss: 0.7915 - learning_rate: 3.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8507 - loss: 0.4151 - val_accuracy: 0.7100 - val_loss: 0.7904 - learning_rate: 3.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8605 - loss: 0.3862 - val_accuracy: 0.7100 - val_loss: 0.7975 - learning_rate: 3.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8828 - loss: 0.3659 - val_accuracy: 0.7133 - val_loss: 0.8068 - learning_rate: 3.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8835 - loss: 0.3386 - val_accuracy: 0.7167 - val_loss: 0.8184 - learning_rate: 3.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8790 - loss: 0.3333 - val_accuracy: 0.7167 - val_loss: 0.8305 - learning_rate: 3.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8966 - loss: 0.3120 - val_accuracy: 0.7167 - val_loss: 0.8488 - learning_rate: 3.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8947 - loss: 0.3191 - val_accuracy: 0.7133 - val_loss: 0.8566 - learning_rate: 1.5000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9030 - loss: 0.2932 - val_accuracy: 0.7133 - val_loss: 0.8635 - learning_rate: 1.5000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9046 - loss: 0.2965 - val_accuracy: 0.7200 - val_loss: 0.8681 - learning_rate: 1.5000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9000 - loss: 0.3096 - val_accuracy: 0.7133 - val_loss: 0.8776 - learning_rate: 1.5000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9036 - loss: 0.2877 - val_accuracy: 0.7133 - val_loss: 0.8892 - learning_rate: 1.5000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9063 - loss: 0.2820 - val_accuracy: 0.7100 - val_loss: 0.8909 - learning_rate: 7.5000e-05\n",
            "Epoch 22/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2864 - val_accuracy: 0.7133 - val_loss: 0.8917 - learning_rate: 7.5000e-05\n",
            "Epoch 23/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9050 - loss: 0.2762 - val_accuracy: 0.7133 - val_loss: 0.8996 - learning_rate: 7.5000e-05\n",
            "Epoch 24/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9015 - loss: 0.2833 - val_accuracy: 0.7133 - val_loss: 0.9003 - learning_rate: 7.5000e-05\n",
            "Epoch 25/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9116 - loss: 0.2731 - val_accuracy: 0.7133 - val_loss: 0.9071 - learning_rate: 7.5000e-05\n",
            "Epoch 26/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.2748 - val_accuracy: 0.7133 - val_loss: 0.9073 - learning_rate: 3.7500e-05\n",
            "Epoch 27/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.2797 - val_accuracy: 0.7133 - val_loss: 0.9141 - learning_rate: 3.7500e-05\n",
            "Epoch 28/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8967 - loss: 0.2922 - val_accuracy: 0.7133 - val_loss: 0.9145 - learning_rate: 3.7500e-05\n",
            "Epoch 29/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9049 - loss: 0.2835 - val_accuracy: 0.7133 - val_loss: 0.9122 - learning_rate: 3.7500e-05\n",
            "Epoch 30/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9058 - loss: 0.2736 - val_accuracy: 0.7133 - val_loss: 0.9162 - learning_rate: 3.7500e-05\n",
            "Epoch 31/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9068 - loss: 0.2798 - val_accuracy: 0.7133 - val_loss: 0.9162 - learning_rate: 1.8750e-05\n",
            "Epoch 32/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9044 - loss: 0.2712 - val_accuracy: 0.7167 - val_loss: 0.9204 - learning_rate: 1.8750e-05\n",
            "Epoch 33/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9034 - loss: 0.2839 - val_accuracy: 0.7133 - val_loss: 0.9226 - learning_rate: 1.8750e-05\n",
            "Epoch 34/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2696 - val_accuracy: 0.7100 - val_loss: 0.9207 - learning_rate: 1.8750e-05\n",
            "Epoch 35/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.2812 - val_accuracy: 0.7133 - val_loss: 0.9225 - learning_rate: 1.8750e-05\n",
            "Epoch 36/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9043 - loss: 0.2816 - val_accuracy: 0.7100 - val_loss: 0.9262 - learning_rate: 9.3750e-06\n",
            "Epoch 37/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9043 - loss: 0.2749 - val_accuracy: 0.7100 - val_loss: 0.9256 - learning_rate: 9.3750e-06\n",
            "Epoch 38/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2706 - val_accuracy: 0.7100 - val_loss: 0.9277 - learning_rate: 9.3750e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "Seems overfitted to the training set, with discreancy of the accuracies between the training and the validation set."
      ],
      "metadata": {
        "id": "uD3giYW5i1BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_Ensemble.predict(train_vectors)\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "y_train_true_classes = np.argmax(train_labels_nn, axis=1)\n",
        "y_dev_pred = model_Ensemble.predict(dev_vectors)\n",
        "y_dev_pred_classes = np.argmax(y_dev_pred, axis=1)\n",
        "y_dev_true_classes = np.argmax(dev_labels_nn, axis=1)\n",
        "\n",
        "# accu\n",
        "train_accuracy = accuracy_score(y_train_true_classes, y_train_pred_classes)\n",
        "dev_accuracy = accuracy_score(y_dev_true_classes, y_dev_pred_classes)\n",
        "\n",
        "print(f\"Train accuracy : {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Dev accuracy   : {dev_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DZhgYppiJGE",
        "outputId": "72fa5176-89bb-42b4-dd71-6e49232804ad"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Train accuracy : 93.89%\n",
            "Dev accuracy   : 72.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try XGBoost, Logistic Regression and SVM"
      ],
      "metadata": {
        "id": "IZMaZOiLk3hh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model_xgb = xgb.XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=3,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_alpha=0.1,\n",
        "    reg_lambda=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model_xgb.fit(train_vectors, train_labels)\n",
        "y_pred = model_xgb.predict(dev_vectors)\n",
        "\n",
        "acc = accuracy_score(dev_labels, y_pred)\n",
        "print(f\"Accuracy XGBoost : {acc:.4f}\")"
      ],
      "metadata": {
        "id": "V7_m2xBdlLLS",
        "outputId": "eabda8d3-4c60-4990-a6f2-3aff8bd57202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy XGBoost : 0.6600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_lr = LogisticRegression(max_iter=500, multi_class='multinomial', solver='lbfgs')\n",
        "model_lr.fit(train_vectors, train_labels)\n",
        "y_pred = model_lr.predict(dev_vectors)\n",
        "\n",
        "acc = accuracy_score(dev_labels, y_pred)\n",
        "print(f\"Accuracy Logistic Regression : {acc:.4f}\")"
      ],
      "metadata": {
        "id": "wIj_yjjUlLOn",
        "outputId": "993ea97f-836a-49ec-e8e0-bba0bda83278",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Logistic Regression : 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model_svm = SVC(C=1, kernel='rbf', probability=True)\n",
        "model_svm.fit(train_vectors, train_labels)\n",
        "y_pred = model_svm.predict(dev_vectors)\n",
        "\n",
        "acc = accuracy_score(dev_labels, y_pred)\n",
        "print(f\"Accuracy SVM : {acc:.4f}\")"
      ],
      "metadata": {
        "id": "gnYFUYzUk5nY",
        "outputId": "38082b61-cd43-46a0-dbcd-c21f4768d383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy SVM : 0.6633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportation of the ensemble model"
      ],
      "metadata": {
        "id": "9NsWxJ7JmGPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login, create_repo, upload_folder\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "login(token=\"\")\n",
        "\n",
        "repo_name = \"MNLP-HW1\"\n",
        "repo_id = f\"tgarnier067/{repo_name}\"\n",
        "create_repo(repo_id, exist_ok=True, private=False)\n",
        "model_folder = \"models\"\n",
        "os.makedirs(model_folder, exist_ok=True)\n",
        "\n",
        "models = {\n",
        "    \"model_ensemble\": model_Ensemble\n",
        "}\n",
        "\n",
        "# Save the models in separate files\n",
        "for model_name, model in models.items():\n",
        "    model_file_path = os.path.join(model_folder, f\"{model_name}.keras\")\n",
        "    model.save(model_file_path)\n",
        "\n",
        "readme_content = \"\"\"# MNLP HW1 Models\n",
        "This repository contains multiple models trained for different tasks. Each model is saved as a separate `.keras` file.\n",
        "\"\"\"\n",
        "\n",
        "with open(os.path.join(model_folder, \"README.md\"), \"w\") as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "upload_folder(\n",
        "    repo_id=repo_id,\n",
        "    folder_path=model_folder,\n",
        "    path_in_repo=\"\"\n",
        ")\n",
        "\n",
        "print(f\"All models have been successfully uploaded to Hugging Face in the repo {repo_id}!\")"
      ],
      "metadata": {
        "id": "G1J9Ds4DmJSP",
        "outputId": "ea703429-b3ff-4a5d-d74c-1545dab7746e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py:9561: UserWarning: Warnings while validating metadata in README.md:\n",
            "- empty or missing yaml metadata in repo card\n",
            "  warnings.warn(f\"Warnings while validating metadata in README.md:\\n{message}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All models have been successfully uploaded to Hugging Face in the repo tgarnier067/MNLP-HW1!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN model only"
      ],
      "metadata": {
        "id": "Gbfurz5Vdwz8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "train_labels = df_train_description['label']\n",
        "dev_labels = dev_df_description['label']\n",
        "\n",
        "train_labels_nn = to_categorical(train_labels, num_classes=3)\n",
        "dev_labels_nn = to_categorical(dev_labels, num_classes=3)\n",
        "\n",
        "train_vectors = logits_train_model_photos\n",
        "dev_vectors = logits_dev_model_photos\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n",
        "model_photos = models.Sequential()\n",
        "\n",
        "model_photos.add(layers.Input(shape=(3,), name='input_layer'))\n",
        "\n",
        "model_photos.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model_photos.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model_photos.fit(\n",
        "    train_vectors, train_labels_nn,\n",
        "    validation_data=(dev_vectors, dev_labels_nn),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUXw1suWd35_",
        "outputId": "e9b4e196-5be7-41f1-a811-955215a2e07a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.4200 - loss: 4.2080 - val_accuracy: 0.4567 - val_loss: 3.5064 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4325 - loss: 3.3012 - val_accuracy: 0.4467 - val_loss: 3.0949 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4541 - loss: 2.7731 - val_accuracy: 0.4533 - val_loss: 2.6887 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4767 - loss: 2.0359 - val_accuracy: 0.4600 - val_loss: 2.3034 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4844 - loss: 1.4612 - val_accuracy: 0.4533 - val_loss: 1.9469 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5203 - loss: 0.9706 - val_accuracy: 0.4767 - val_loss: 1.7570 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6102 - loss: 0.7740 - val_accuracy: 0.4833 - val_loss: 1.7335 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6418 - loss: 0.7215 - val_accuracy: 0.4900 - val_loss: 1.7537 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6594 - loss: 0.6809 - val_accuracy: 0.4900 - val_loss: 1.7797 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6507 - loss: 0.6734 - val_accuracy: 0.4867 - val_loss: 1.8083 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6572 - loss: 0.6656 - val_accuracy: 0.4933 - val_loss: 1.8369 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6669 - loss: 0.6604 - val_accuracy: 0.4967 - val_loss: 1.8642 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6489 - loss: 0.6666 - val_accuracy: 0.5000 - val_loss: 1.8777 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6703 - loss: 0.6541 - val_accuracy: 0.5000 - val_loss: 1.8910 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6542 - loss: 0.6518 - val_accuracy: 0.5000 - val_loss: 1.9055 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6609 - loss: 0.6514 - val_accuracy: 0.4967 - val_loss: 1.9191 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6506 - loss: 0.6636 - val_accuracy: 0.4967 - val_loss: 1.9325 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6572 - loss: 0.6490 - val_accuracy: 0.4967 - val_loss: 1.9396 - learning_rate: 2.5000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6520 - loss: 0.6586 - val_accuracy: 0.4967 - val_loss: 1.9468 - learning_rate: 2.5000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6590 - loss: 0.6538 - val_accuracy: 0.4967 - val_loss: 1.9544 - learning_rate: 2.5000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6700 - loss: 0.6368 - val_accuracy: 0.4967 - val_loss: 1.9617 - learning_rate: 2.5000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6622 - loss: 0.6467 - val_accuracy: 0.4933 - val_loss: 1.9700 - learning_rate: 2.5000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6602 - loss: 0.6439 - val_accuracy: 0.4933 - val_loss: 1.9738 - learning_rate: 1.2500e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6659 - loss: 0.6485 - val_accuracy: 0.4933 - val_loss: 1.9782 - learning_rate: 1.2500e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6620 - loss: 0.6446 - val_accuracy: 0.4933 - val_loss: 1.9822 - learning_rate: 1.2500e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6576 - loss: 0.6433 - val_accuracy: 0.4933 - val_loss: 1.9870 - learning_rate: 1.2500e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6578 - loss: 0.6390 - val_accuracy: 0.4933 - val_loss: 1.9916 - learning_rate: 1.2500e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6650 - loss: 0.6447 - val_accuracy: 0.4933 - val_loss: 1.9940 - learning_rate: 6.2500e-05\n",
            "Epoch 29/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6519 - loss: 0.6611 - val_accuracy: 0.4933 - val_loss: 1.9964 - learning_rate: 6.2500e-05\n",
            "Epoch 30/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6627 - loss: 0.6443 - val_accuracy: 0.4933 - val_loss: 1.9991 - learning_rate: 6.2500e-05\n",
            "Epoch 31/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6615 - loss: 0.6479 - val_accuracy: 0.4933 - val_loss: 2.0018 - learning_rate: 6.2500e-05\n",
            "Epoch 32/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6663 - loss: 0.6374 - val_accuracy: 0.4933 - val_loss: 2.0045 - learning_rate: 6.2500e-05\n",
            "Epoch 33/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6580 - loss: 0.6462 - val_accuracy: 0.4933 - val_loss: 2.0060 - learning_rate: 3.1250e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_photos.predict(train_vectors)\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "y_train_true_classes = np.argmax(train_labels_nn, axis=1)\n",
        "y_dev_pred = model_photos.predict(dev_vectors)\n",
        "y_dev_pred_classes = np.argmax(y_dev_pred, axis=1)\n",
        "y_dev_true_classes = np.argmax(dev_labels_nn, axis=1)\n",
        "\n",
        "# accu\n",
        "train_accuracy = accuracy_score(y_train_true_classes, y_train_pred_classes)\n",
        "dev_accuracy = accuracy_score(y_dev_true_classes, y_dev_pred_classes)\n",
        "\n",
        "print(f\"Train accuracy : {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Dev accuracy   : {dev_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKdhIK-xeWGV",
        "outputId": "29866719-4813-440e-f595-ba85ef707062"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "Train accuracy : 65.93%\n",
            "Dev accuracy   : 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description model only"
      ],
      "metadata": {
        "id": "TcCAKAf6eiJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "train_labels = df_train_description['label']\n",
        "dev_labels = dev_df_description['label']\n",
        "\n",
        "train_labels_nn = to_categorical(train_labels, num_classes=3)\n",
        "dev_labels_nn = to_categorical(dev_labels, num_classes=3)\n",
        "\n",
        "train_vectors = logits_train_model_description\n",
        "dev_vectors = logits_dev_model_descriptions\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n",
        "model_description = models.Sequential()\n",
        "\n",
        "model_description.add(layers.Input(shape=(3,), name='input_layer'))\n",
        "\n",
        "model_description.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model_description.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model_description.fit(\n",
        "    train_vectors, train_labels_nn,\n",
        "    validation_data=(dev_vectors, dev_labels_nn),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "outputId": "2ca459d1-2499-4155-fde6-c04861bafda6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDACNBKlem-B"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.4975 - loss: 2.0145 - val_accuracy: 0.6067 - val_loss: 1.1828 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4917 - loss: 1.5174 - val_accuracy: 0.6233 - val_loss: 0.9724 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5032 - loss: 1.0860 - val_accuracy: 0.6300 - val_loss: 0.8366 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5661 - loss: 0.7911 - val_accuracy: 0.6667 - val_loss: 0.7782 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6846 - loss: 0.6225 - val_accuracy: 0.6933 - val_loss: 0.7666 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7489 - loss: 0.5329 - val_accuracy: 0.6967 - val_loss: 0.7724 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7763 - loss: 0.4780 - val_accuracy: 0.6967 - val_loss: 0.7827 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7887 - loss: 0.4509 - val_accuracy: 0.6933 - val_loss: 0.7937 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8079 - loss: 0.4145 - val_accuracy: 0.6867 - val_loss: 0.8050 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8169 - loss: 0.3905 - val_accuracy: 0.6867 - val_loss: 0.8155 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8224 - loss: 0.3757 - val_accuracy: 0.6933 - val_loss: 0.8206 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8276 - loss: 0.3679 - val_accuracy: 0.6900 - val_loss: 0.8256 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8374 - loss: 0.3624 - val_accuracy: 0.6833 - val_loss: 0.8308 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8348 - loss: 0.3572 - val_accuracy: 0.6767 - val_loss: 0.8358 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.3451 - val_accuracy: 0.6700 - val_loss: 0.8408 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8557 - loss: 0.3355 - val_accuracy: 0.6800 - val_loss: 0.8431 - learning_rate: 2.5000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8520 - loss: 0.3423 - val_accuracy: 0.6800 - val_loss: 0.8454 - learning_rate: 2.5000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8613 - loss: 0.3388 - val_accuracy: 0.6800 - val_loss: 0.8481 - learning_rate: 2.5000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3365 - val_accuracy: 0.6833 - val_loss: 0.8504 - learning_rate: 2.5000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8602 - loss: 0.3340 - val_accuracy: 0.6833 - val_loss: 0.8531 - learning_rate: 2.5000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8723 - loss: 0.3146 - val_accuracy: 0.6800 - val_loss: 0.8547 - learning_rate: 1.2500e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.3358 - val_accuracy: 0.6800 - val_loss: 0.8561 - learning_rate: 1.2500e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8640 - loss: 0.3296 - val_accuracy: 0.6833 - val_loss: 0.8575 - learning_rate: 1.2500e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3232 - val_accuracy: 0.6833 - val_loss: 0.8591 - learning_rate: 1.2500e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8672 - loss: 0.3241 - val_accuracy: 0.6833 - val_loss: 0.8606 - learning_rate: 1.2500e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8685 - loss: 0.3258 - val_accuracy: 0.6833 - val_loss: 0.8614 - learning_rate: 6.2500e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_description.predict(train_vectors)\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "y_train_true_classes = np.argmax(train_labels_nn, axis=1)\n",
        "y_dev_pred = model_description.predict(dev_vectors)\n",
        "y_dev_pred_classes = np.argmax(y_dev_pred, axis=1)\n",
        "y_dev_true_classes = np.argmax(dev_labels_nn, axis=1)\n",
        "\n",
        "# accu\n",
        "train_accuracy = accuracy_score(y_train_true_classes, y_train_pred_classes)\n",
        "dev_accuracy = accuracy_score(y_dev_true_classes, y_dev_pred_classes)\n",
        "\n",
        "print(f\"Train accuracy : {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Dev accuracy   : {dev_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "outputId": "ee314370-7136-42a7-ebfe-046c2c1735f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWgigCP7em-D"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Train accuracy : 76.98%\n",
            "Dev accuracy   : 69.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Features model only"
      ],
      "metadata": {
        "id": "cF9vf9ARfFvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
        "\n",
        "train_labels = df_train_description['label']\n",
        "dev_labels = dev_df_description['label']\n",
        "\n",
        "train_labels_nn = to_categorical(train_labels, num_classes=3)\n",
        "dev_labels_nn = to_categorical(dev_labels, num_classes=3)\n",
        "\n",
        "train_vectors = logits_train_model_features\n",
        "dev_vectors = logits_dev_model_features\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n",
        "model_features = models.Sequential()\n",
        "\n",
        "model_features.add(layers.Input(shape=(3,), name='input_layer'))\n",
        "\n",
        "model_features.add(layers.Dense(3, activation='softmax'))\n",
        "\n",
        "model_features.compile(optimizer=Adam(learning_rate=1e-3),\n",
        "                       loss='categorical_crossentropy',\n",
        "                       metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model_features.fit(\n",
        "    train_vectors, train_labels_nn,\n",
        "    validation_data=(dev_vectors, dev_labels_nn),\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stop, reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "outputId": "68a2b377-ce54-40c6-c716-9585d1bfdd17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vGfv5EOfULN"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7750 - loss: 0.5525 - val_accuracy: 0.7500 - val_loss: 0.6341 - learning_rate: 0.0010\n",
            "Epoch 2/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7719 - loss: 0.5636 - val_accuracy: 0.7500 - val_loss: 0.6340 - learning_rate: 0.0010\n",
            "Epoch 3/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7675 - loss: 0.5631 - val_accuracy: 0.7500 - val_loss: 0.6334 - learning_rate: 0.0010\n",
            "Epoch 4/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7711 - loss: 0.5533 - val_accuracy: 0.7500 - val_loss: 0.6331 - learning_rate: 0.0010\n",
            "Epoch 5/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7760 - loss: 0.5488 - val_accuracy: 0.7500 - val_loss: 0.6330 - learning_rate: 0.0010\n",
            "Epoch 6/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7744 - loss: 0.5415 - val_accuracy: 0.7533 - val_loss: 0.6319 - learning_rate: 0.0010\n",
            "Epoch 7/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7800 - loss: 0.5405 - val_accuracy: 0.7533 - val_loss: 0.6309 - learning_rate: 0.0010\n",
            "Epoch 8/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7703 - loss: 0.5453 - val_accuracy: 0.7533 - val_loss: 0.6305 - learning_rate: 0.0010\n",
            "Epoch 9/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.5489 - val_accuracy: 0.7533 - val_loss: 0.6299 - learning_rate: 0.0010\n",
            "Epoch 10/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 0.5477 - val_accuracy: 0.7500 - val_loss: 0.6296 - learning_rate: 0.0010\n",
            "Epoch 11/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7720 - loss: 0.5485 - val_accuracy: 0.7533 - val_loss: 0.6288 - learning_rate: 0.0010\n",
            "Epoch 12/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7654 - loss: 0.5605 - val_accuracy: 0.7533 - val_loss: 0.6290 - learning_rate: 0.0010\n",
            "Epoch 13/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7723 - loss: 0.5455 - val_accuracy: 0.7533 - val_loss: 0.6283 - learning_rate: 0.0010\n",
            "Epoch 14/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7749 - loss: 0.5458 - val_accuracy: 0.7500 - val_loss: 0.6278 - learning_rate: 0.0010\n",
            "Epoch 15/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7662 - loss: 0.5580 - val_accuracy: 0.7467 - val_loss: 0.6278 - learning_rate: 0.0010\n",
            "Epoch 16/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7722 - loss: 0.5497 - val_accuracy: 0.7500 - val_loss: 0.6271 - learning_rate: 0.0010\n",
            "Epoch 17/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7730 - loss: 0.5390 - val_accuracy: 0.7500 - val_loss: 0.6268 - learning_rate: 0.0010\n",
            "Epoch 18/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7654 - loss: 0.5591 - val_accuracy: 0.7467 - val_loss: 0.6264 - learning_rate: 0.0010\n",
            "Epoch 19/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7731 - loss: 0.5475 - val_accuracy: 0.7500 - val_loss: 0.6266 - learning_rate: 0.0010\n",
            "Epoch 20/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7733 - loss: 0.5473 - val_accuracy: 0.7467 - val_loss: 0.6263 - learning_rate: 0.0010\n",
            "Epoch 21/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7624 - loss: 0.5727 - val_accuracy: 0.7500 - val_loss: 0.6258 - learning_rate: 0.0010\n",
            "Epoch 22/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7650 - loss: 0.5570 - val_accuracy: 0.7500 - val_loss: 0.6256 - learning_rate: 0.0010\n",
            "Epoch 23/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7748 - loss: 0.5452 - val_accuracy: 0.7467 - val_loss: 0.6257 - learning_rate: 0.0010\n",
            "Epoch 24/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7740 - loss: 0.5508 - val_accuracy: 0.7467 - val_loss: 0.6253 - learning_rate: 0.0010\n",
            "Epoch 25/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7683 - loss: 0.5543 - val_accuracy: 0.7467 - val_loss: 0.6254 - learning_rate: 0.0010\n",
            "Epoch 26/200\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7741 - loss: 0.5428 - val_accuracy: 0.7467 - val_loss: 0.6248 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_pred = model_features.predict(train_vectors)\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "y_train_true_classes = np.argmax(train_labels_nn, axis=1)\n",
        "y_dev_pred = model_features.predict(dev_vectors)\n",
        "y_dev_pred_classes = np.argmax(y_dev_pred, axis=1)\n",
        "y_dev_true_classes = np.argmax(dev_labels_nn, axis=1)\n",
        "\n",
        "# accu\n",
        "train_accuracy = accuracy_score(y_train_true_classes, y_train_pred_classes)\n",
        "dev_accuracy = accuracy_score(y_dev_true_classes, y_dev_pred_classes)\n",
        "\n",
        "print(f\"Train accuracy : {train_accuracy * 100:.2f}%\")\n",
        "print(f\"Dev accuracy   : {dev_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "DhTKYcAFfULQ",
        "outputId": "aa87f90e-a2a2-4843-bdc0-65e3ca4a66c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m196/196\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Train accuracy : 77.01%\n",
            "Dev accuracy   : 75.33%\n"
          ]
        }
      ]
    }
  ]
}